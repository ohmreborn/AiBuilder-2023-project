
# à¸à¸²à¸£à¸£à¸§à¸šà¸£à¸§à¸¡à¹à¸¥à¸°à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥

à¸à¹ˆà¸­à¸™à¸­à¸·à¹ˆà¸™à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Package à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¸à¹ˆà¸­à¸™
``` python
!pip install -q datasets
```
à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™à¸à¹‡à¹‚à¸«à¸¥à¸”à¸¡à¸²
``` python
from datasets import load_dataset
datafile = {'train':'unified_abstract_infill.jsonl'}
data = load_dataset('laion/OIG',data_files=datafile)
print(data)
```
à¸—à¸µà¸™à¸µà¹ˆà¸à¹‡à¹€à¸¥à¸·à¸­à¸ feature à¸—à¸µà¹ˆà¹€à¸£à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ à¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹ˆà¸²à¸™à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹„à¸”à¹‰à¸—à¸µà¹ˆ (Medium)[]
``` python
data = data['train'].filter(lambda x: x['text'].startswith('Background:'))
print(data)
```
à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™à¸à¹‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
``` python
import numpy as np
import re
```
``` python
def setup(data):
  conversation = data['text'].split('<human>:',1)
  conversation[1] = '<human>:' + conversation[1]
  conversation[0] = conversation[0][11:]
  conversation[0] = re.sub('ğŸ˜ƒğŸ§˜ğŸ˜‚ğŸŒğŸğŸš—ğŸ“ğŸ‰â¤ğŸ†ğŸ‘¨ğŸ‘©ğŸ‘§','',conversation[0])
  conversation[1] = x = re.sub('http.+?', '',conversation[1] )
  return {'Background:':conversation[0],
          '<human>:_<bot>:':conversation[1]
          }
```
``` python
data = data.map(setup)
print(data)
```
save file à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸­à¸²à¹„à¸›à¹€à¸—à¸£à¸™à¸—à¸µà¸«à¸¥à¸±à¸‡
``` python
data.to_json('output.jsonl')
```

