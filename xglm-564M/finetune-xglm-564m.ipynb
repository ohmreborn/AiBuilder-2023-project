{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers<=4.28.0\n!pip install sentencepiece\n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T13:23:32.094174Z","iopub.execute_input":"2023-05-06T13:23:32.094517Z","iopub.status.idle":"2023-05-06T13:23:53.560093Z","shell.execute_reply.started":"2023-05-06T13:23:32.094484Z","shell.execute_reply":"2023-05-06T13:23:53.559005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport os\nfrom typing import Union,List\nimport sys\n\nimport torch\nfrom transformers import XGLMTokenizer, XGLMForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\nfrom datasets import load_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:23:53.562452Z","iopub.execute_input":"2023-05-06T13:23:53.563103Z","iopub.status.idle":"2023-05-06T13:24:04.272180Z","shell.execute_reply.started":"2023-05-06T13:23:53.563064Z","shell.execute_reply":"2023-05-06T13:24:04.271310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(base_model:str=\"facebook/xglm-564M\"):\n    tokenizer = XGLMTokenizer.from_pretrained(base_model)\n    model = XGLMForCausalLM.from_pretrained(base_model,\n                                           torch_dtype=torch.float16)\n    return model,tokenizer\nmodel,tokenizer = load_model()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:24:04.278128Z","iopub.execute_input":"2023-05-06T13:24:04.278768Z","iopub.status.idle":"2023-05-06T13:25:25.153432Z","shell.execute_reply.started":"2023-05-06T13:24:04.278737Z","shell.execute_reply":"2023-05-06T13:25:25.152542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokens = ['<human>:', '<bot>:']\n\ntokenizer.add_tokens(list(new_tokens))\n\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:25.155010Z","iopub.execute_input":"2023-05-06T13:25:25.155357Z","iopub.status.idle":"2023-05-06T13:25:44.187622Z","shell.execute_reply.started":"2023-05-06T13:25:25.155326Z","shell.execute_reply":"2023-05-06T13:25:44.186723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?export=download&id=1jbbUtwgwoSQgGnXxzTh-nMReVzEU7ZTU&confirm=t&uuid=d79e2e78-51de-466f-9ceb-3944606141a2&at=AKKF8vwcgi95TGSnSQUNCKx4NTqS:1682865249145'\noutput = 'output.jsonl'\ngdown.download(url, output, quiet=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:44.189075Z","iopub.execute_input":"2023-05-06T13:25:44.190161Z","iopub.status.idle":"2023-05-06T13:25:55.467550Z","shell.execute_reply.started":"2023-05-06T13:25:44.190126Z","shell.execute_reply":"2023-05-06T13:25:55.466504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# format data like <sep> context <human>...<bot>...\ndef preprocess(prompt):\n    data = tokenizer(\n        prompt,\n        truncation=True,\n        max_length=256,\n        padding=False,\n        return_tensors=None,\n    )\n    data['input_ids'].append(tokenizer.eos_token_id)\n    data['attention_mask'].append(1)\n    data = datacol(data)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:55.469194Z","iopub.execute_input":"2023-05-06T13:25:55.470277Z","iopub.status.idle":"2023-05-06T13:25:55.476146Z","shell.execute_reply.started":"2023-05-06T13:25:55.470243Z","shell.execute_reply":"2023-05-06T13:25:55.475138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('json',data_files='/kaggle/working/output.jsonl')\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:55.477742Z","iopub.execute_input":"2023-05-06T13:25:55.478155Z","iopub.status.idle":"2023-05-06T13:25:57.953310Z","shell.execute_reply.started":"2023-05-06T13:25:55.478124Z","shell.execute_reply":"2023-05-06T13:25:57.952399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset['train']\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:57.954894Z","iopub.execute_input":"2023-05-06T13:25:57.955543Z","iopub.status.idle":"2023-05-06T13:25:57.962032Z","shell.execute_reply.started":"2023-05-06T13:25:57.955511Z","shell.execute_reply":"2023-05-06T13:25:57.961079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n# dataset = Dataset.from_dict(dataset['train'][:1000])\n# dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:57.967088Z","iopub.execute_input":"2023-05-06T13:25:57.967846Z","iopub.status.idle":"2023-05-06T13:25:57.971944Z","shell.execute_reply.started":"2023-05-06T13:25:57.967813Z","shell.execute_reply":"2023-05-06T13:25:57.970854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_prompt(prompt):\n    return {'prompt':f\"{prompt['Background:']} {prompt['<human>:']} {prompt['<bot>:']}\"}","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:57.973589Z","iopub.execute_input":"2023-05-06T13:25:57.974314Z","iopub.status.idle":"2023-05-06T13:25:57.981376Z","shell.execute_reply.started":"2023-05-06T13:25:57.974282Z","shell.execute_reply":"2023-05-06T13:25:57.980350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(format_prompt,remove_columns=['Background:', '<human>:', '<bot>:'])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:25:57.983190Z","iopub.execute_input":"2023-05-06T13:25:57.984034Z","iopub.status.idle":"2023-05-06T13:26:06.381135Z","shell.execute_reply.started":"2023-05-06T13:25:57.983992Z","shell.execute_reply":"2023-05-06T13:26:06.380257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# format data like <sep> context <human>...<bot>...<sep>\ndef preprocess(prompt):\n    data = tokenizer(\n        prompt['prompt'],\n        truncation=True,\n        max_length=256,\n        padding=False,\n        return_tensors=None,\n    )\n    data['input_ids'].append(tokenizer.eos_token_id)\n    data['attention_mask'].append(1)\n    data['labels'] = data['input_ids']\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:26:06.382528Z","iopub.execute_input":"2023-05-06T13:26:06.382873Z","iopub.status.idle":"2023-05-06T13:26:06.390489Z","shell.execute_reply.started":"2023-05-06T13:26:06.382842Z","shell.execute_reply":"2023-05-06T13:26:06.387433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(preprocess,remove_columns=['prompt']) \ndataset ","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:26:06.392003Z","iopub.execute_input":"2023-05-06T13:26:06.392330Z","iopub.status.idle":"2023-05-06T13:29:34.397026Z","shell.execute_reply.started":"2023-05-06T13:26:06.392300Z","shell.execute_reply":"2023-05-06T13:29:34.395951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset= dataset.filter(lambda x:x['input_ids'][0] ==2)\ndataset=dataset.filter(lambda x:x['input_ids'][-1] == 2)  \ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:29:34.398671Z","iopub.execute_input":"2023-05-06T13:29:34.399175Z","iopub.status.idle":"2023-05-06T13:30:39.712859Z","shell.execute_reply.started":"2023-05-06T13:29:34.399140Z","shell.execute_reply":"2023-05-06T13:30:39.711944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(\n            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True # ไม่รู้_\n        )","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.714267Z","iopub.execute_input":"2023-05-06T13:30:39.714841Z","iopub.status.idle":"2023-05-06T13:30:39.720003Z","shell.execute_reply.started":"2023-05-06T13:30:39.714792Z","shell.execute_reply":"2023-05-06T13:30:39.718587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample = tokenizer('hell I am your father',\n#                    truncation=True,\n#                    max_length=256,\n#                    padding=False,\n#                    return_tensors=None)\n# sample['labels'] = sample['input_ids']\n# sample","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.721434Z","iopub.execute_input":"2023-05-06T13:30:39.722269Z","iopub.status.idle":"2023-05-06T13:30:39.732732Z","shell.execute_reply.started":"2023-05-06T13:30:39.722236Z","shell.execute_reply":"2023-05-06T13:30:39.731635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_collator([sample])","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.733935Z","iopub.execute_input":"2023-05-06T13:30:39.735025Z","iopub.status.idle":"2023-05-06T13:30:39.741626Z","shell.execute_reply.started":"2023-05-06T13:30:39.734988Z","shell.execute_reply":"2023-05-06T13:30:39.740681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 128\nmini_batch_size = 4\ngradient_accumulation_steps = batch_size //mini_batch_size\nprint(gradient_accumulation_steps)\ntrain_dataloader = DataLoader(\n    dataset, shuffle=True, batch_size=4, collate_fn=data_collator\n)\nprint(len(train_dataloader))\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.742860Z","iopub.execute_input":"2023-05-06T13:30:39.743648Z","iopub.status.idle":"2023-05-06T13:30:39.751231Z","shell.execute_reply.started":"2023-05-06T13:30:39.743616Z","shell.execute_reply":"2023-05-06T13:30:39.750090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW,get_scheduler\nimport math\noptimizer = AdamW(model.parameters(), lr=3e-5)\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=100,\n    num_training_steps=math.ceil(num_training_steps/gradient_accumulation_steps),\n)\nprint(num_training_steps,math.ceil(num_training_steps/gradient_accumulation_steps)) # Learning Rate Schedules","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.753523Z","iopub.execute_input":"2023-05-06T13:30:39.754083Z","iopub.status.idle":"2023-05-06T13:30:39.769300Z","shell.execute_reply.started":"2023-05-06T13:30:39.754049Z","shell.execute_reply":"2023-05-06T13:30:39.768383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # ตรงนี้สำหรับคนใช้ GPU/CPU ในการเทรน\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:39.770436Z","iopub.execute_input":"2023-05-06T13:30:39.771284Z","iopub.status.idle":"2023-05-06T13:30:44.445579Z","shell.execute_reply.started":"2023-05-06T13:30:39.771252Z","shell.execute_reply":"2023-05-06T13:30:44.444421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n#     data = next(iter(train_dataloader))\n#     data = {k:v.to(device) for k,v in data.items()}\n#     print(model(**data))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:44.446961Z","iopub.execute_input":"2023-05-06T13:30:44.447982Z","iopub.status.idle":"2023-05-06T13:30:44.454350Z","shell.execute_reply.started":"2023-05-06T13:30:44.447945Z","shell.execute_reply":"2023-05-06T13:30:44.453200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir_min_loss = 'xglm-checkpoint-min-loss'\nOPTIMIZER_NAME = \"optimizer.pt\"\nSCHEDULER_NAME = \"scheduler.pt\"","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:44.456476Z","iopub.execute_input":"2023-05-06T13:30:44.456890Z","iopub.status.idle":"2023-05-06T13:30:44.462554Z","shell.execute_reply.started":"2023-05-06T13:30:44.456858Z","shell.execute_reply":"2023-05-06T13:30:44.461571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('hello world')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\nprint('start_training')\nfor epoch in range(num_epochs):\n    for index,data in enumerate(train_dataloader):\n        data = {k:v.to(device) for k,v in data.items()}\n        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(**data)\n            loss = outputs.loss / gradient_accumulation_steps\n            loss.backward()\n        \n        if (index + 1) % gradient_accumulation_steps == 0:\n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            if (index+1) % gradient_accumulation_steps**2 == 0:\n                print(epoch,index+1,(index+1)%gradient_accumulation_steps,loss)\n    model.save_pretrained(output_dir_min_loss) \n    with open(os.path.join(output_dir_min_loss, 'loss.txt'),'w') as f:\n        text = f'{epoch},{index+1},{(index+1)%gradient_accumulation_steps},{loss.item()}'\n        f.write(text)\n    torch.save(optimizer.state_dict(), os.path.join(output_dir_min_loss, OPTIMIZER_NAME))\n    torch.save(lr_scheduler.state_dict(), os.path.join(output_dir_min_loss, SCHEDULER_NAME))\n             \n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:57.572127Z","iopub.execute_input":"2023-05-06T13:30:57.572478Z","iopub.status.idle":"2023-05-06T13:31:10.650623Z","shell.execute_reply.started":"2023-05-06T13:30:57.572450Z","shell.execute_reply":"2023-05-06T13:31:10.649346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir_latest_version = 'xglm-checkpoint-latest-version'\nmodel.save_pretrained(output_dir_latest_version) \nwith open(os.path.join(output_dir_latest_version, 'loss.txt'),'w') as f:\n    f.write(str(loss.item()))\ntorch.save(optimizer.state_dict(), os.path.join(output_dir_latest_version, OPTIMIZER_NAME))\ntorch.save(lr_scheduler.state_dict(), os.path.join(output_dir_latest_version, SCHEDULER_NAME))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:51.937578Z","iopub.status.idle":"2023-05-06T13:30:51.938072Z","shell.execute_reply.started":"2023-05-06T13:30:51.937796Z","shell.execute_reply":"2023-05-06T13:30:51.937819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('end')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T13:30:51.939725Z","iopub.status.idle":"2023-05-06T13:30:51.940202Z","shell.execute_reply.started":"2023-05-06T13:30:51.939966Z","shell.execute_reply":"2023-05-06T13:30:51.939988Z"},"trusted":true},"execution_count":null,"outputs":[]}]}