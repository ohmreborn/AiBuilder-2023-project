{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/accelerate\n!pip install transformers\n!pip install sentencepiece\n!pip install datasets\n!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\ncpu_cores = multiprocessing.cpu_count()\nprint(cpu_cores)","metadata":{"id":"WGCekq2qTwLZ","outputId":"3c002673-f10d-4434-c70c-986980ea19bc","execution":{"iopub.status.busy":"2023-05-09T21:26:53.452426Z","iopub.execute_input":"2023-05-09T21:26:53.453154Z","iopub.status.idle":"2023-05-09T21:26:53.464414Z","shell.execute_reply.started":"2023-05-09T21:26:53.453109Z","shell.execute_reply":"2023-05-09T21:26:53.463346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport os\nfrom typing import Union,List\nimport sys\n\nimport torch\nfrom transformers import XGLMTokenizer, XGLMForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, GenerationConfig\nfrom datasets import load_dataset\n","metadata":{"id":"q761pOlTTxQQ","execution":{"iopub.status.busy":"2023-05-09T21:26:53.644205Z","iopub.execute_input":"2023-05-09T21:26:53.644846Z","iopub.status.idle":"2023-05-09T21:26:59.176230Z","shell.execute_reply.started":"2023-05-09T21:26:53.644810Z","shell.execute_reply":"2023-05-09T21:26:59.175231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('load_model')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T21:26:59.178316Z","iopub.execute_input":"2023-05-09T21:26:59.179112Z","iopub.status.idle":"2023-05-09T21:26:59.184093Z","shell.execute_reply.started":"2023-05-09T21:26:59.179074Z","shell.execute_reply":"2023-05-09T21:26:59.183092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(base_model:str=\"facebook/xglm-564M\"):\n    tokenizer = XGLMTokenizer.from_pretrained(base_model)\n    model = XGLMForCausalLM.from_pretrained(base_model,\n                                           torch_dtype=torch.float16)\n    new_tokens = ['<human>:', '<bot>:']\n    tokenizer.add_tokens(list(new_tokens))\n    model.resize_token_embeddings(len(tokenizer))\n    \n    return model,tokenizer\nmodel,tokenizer = load_model()","metadata":{"id":"f40mi91PTy0Z","outputId":"8457d1d2-5b70-46ef-c48a-b9370dc8cc92","scrolled":true,"execution":{"iopub.status.busy":"2023-05-09T21:26:59.185678Z","iopub.execute_input":"2023-05-09T21:26:59.186449Z","iopub.status.idle":"2023-05-09T21:27:51.867215Z","shell.execute_reply.started":"2023-05-09T21:26:59.186410Z","shell.execute_reply":"2023-05-09T21:27:51.866168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?export=download&id=1jbbUtwgwoSQgGnXxzTh-nMReVzEU7ZTU&confirm=t&uuid=d79e2e78-51de-466f-9ceb-3944606141a2&at=AKKF8vwcgi95TGSnSQUNCKx4NTqS:1682865249145'\noutput = 'output.jsonl'\ngdown.download(url, output, quiet=False)\n","metadata":{"id":"ChBl6Lv2T7np","outputId":"c0e25fe6-908d-465f-d606-33aad02306ed","execution":{"iopub.status.busy":"2023-05-09T21:27:51.869779Z","iopub.execute_input":"2023-05-09T21:27:51.870132Z","iopub.status.idle":"2023-05-09T21:27:53.572072Z","shell.execute_reply.started":"2023-05-09T21:27:51.870103Z","shell.execute_reply":"2023-05-09T21:27:53.570874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndatasets = load_dataset('json',data_files='output.jsonl')\nprint(datasets)","metadata":{"id":"h7BnyMvUT895","outputId":"d05905e1-6e9e-461a-b831-69f7ce3020cf","execution":{"iopub.status.busy":"2023-05-09T21:30:23.205684Z","iopub.execute_input":"2023-05-09T21:30:23.206107Z","iopub.status.idle":"2023-05-09T21:30:23.396945Z","shell.execute_reply.started":"2023-05-09T21:30:23.206068Z","shell.execute_reply":"2023-05-09T21:30:23.396024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_prompt(prompt):\n    return {'prompt':f\"{prompt['Background:']} <human>: {prompt['<human>:']} <bot>: {prompt['<bot>:']}\"}\n# format data like  context ......\ndef preprocess(prompt):\n    data = tokenizer(\n        prompt['prompt'],\n        truncation=True,\n        max_length=256,\n        padding=False,\n        return_tensors=None,\n    )\n    data['input_ids'].append(tokenizer.eos_token_id)\n    data['attention_mask'].append(1)\n    data['labels'] = data['input_ids'].copy()\n    return data","metadata":{"id":"40Rk80IOT9ae","execution":{"iopub.status.busy":"2023-05-09T21:27:55.322818Z","iopub.execute_input":"2023-05-09T21:27:55.323842Z","iopub.status.idle":"2023-05-09T21:27:55.331238Z","shell.execute_reply.started":"2023-05-09T21:27:55.323806Z","shell.execute_reply":"2023-05-09T21:27:55.329923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('preprocess')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T21:27:55.332715Z","iopub.execute_input":"2023-05-09T21:27:55.333487Z","iopub.status.idle":"2023-05-09T21:27:55.348903Z","shell.execute_reply.started":"2023-05-09T21:27:55.333455Z","shell.execute_reply":"2023-05-09T21:27:55.347897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from datasets import Dataset\n# datasets = Dataset.from_dict(datasets['train'][:20_000]) # sample data for test\ndatasets = datasets['train']\ndatasets = datasets.map(format_prompt,remove_columns=['Background:', '<human>:', '<bot>:'],num_proc=cpu_cores)\nprint(datasets['prompt'][0])\ndatasets = datasets.map(lambda x:{'token':len(tokenizer.tokenize(x['prompt']))},num_proc=cpu_cores)\ndatasets = datasets.filter(lambda x:x['token']<255,num_proc=cpu_cores)\ndatasets = datasets.map(preprocess,remove_columns=['prompt','token'],num_proc=cpu_cores) \ndatasets = datasets.filter(lambda x:x['input_ids'][0] == 2,num_proc=cpu_cores)\ndatasets = datasets.filter(lambda x:x['input_ids'][-1] == 2,num_proc=cpu_cores)  \n\ndatasets","metadata":{"id":"_F9suuHoT_eI","outputId":"e2f89ba4-469a-4a1c-d683-05f15e036575","execution":{"iopub.status.busy":"2023-05-09T21:30:30.349767Z","iopub.execute_input":"2023-05-09T21:30:30.350441Z","iopub.status.idle":"2023-05-09T21:31:20.594724Z","shell.execute_reply.started":"2023-05-09T21:30:30.350407Z","shell.execute_reply":"2023-05-09T21:31:20.593717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(\n            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True \n        )","metadata":{"id":"s0nj51BvUJK_","execution":{"iopub.status.busy":"2023-05-09T21:31:37.493342Z","iopub.execute_input":"2023-05-09T21:31:37.493756Z","iopub.status.idle":"2023-05-09T21:31:37.499130Z","shell.execute_reply.started":"2023-05-09T21:31:37.493717Z","shell.execute_reply":"2023-05-09T21:31:37.498067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW,get_scheduler\nfrom torch.cuda.amp import  GradScaler\nimport math\ndef train(model):\n\n    batch_size = 128\n    mini_batch_size = 4\n    gradient_accumulation_steps = batch_size //mini_batch_size\n    train_dataloader = DataLoader(\n        datasets, shuffle=True, batch_size=mini_batch_size, collate_fn=data_collator\n    )\n    \n    accelerator = Accelerator(gradient_accumulation_steps=gradient_accumulation_steps)\n    \n    num_epochs = 6\n    n_gpus = torch.cuda.device_count()\n    l_data_loader = len(train_dataloader)\n    num_training_steps = num_epochs * l_data_loader\n\n    optimizer = AdamW(model.parameters(), lr=3e-7)\n    lr_scheduler = get_scheduler(\n      \"linear\",\n      optimizer=optimizer,\n      num_warmup_steps=100,\n      num_training_steps=num_training_steps,\n    )\n    accelerator.print(num_training_steps)\n    \n    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(model, optimizer, train_dataloader, lr_scheduler)\n\n    accelerator.print('start-training')\n    try :\n        for epoch in range(num_epochs):\n            for index,data in enumerate(train_dataloader):\n                with accelerator.accumulate(model):\n                    with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n                        outputs = model(**data)\n                        loss = outputs.loss \n                        accelerator.backward(loss)\n                        optimizer.step()\n                        lr_scheduler.step()\n                        optimizer.zero_grad()\n            accelerator.print(epoch,index+1,loss)\n                    \n        accelerator.wait_for_everyone() \n        model = accelerator.unwrap_model(model)\n        model.save_pretrained('checkpoint', is_main_process=accelerator.is_main_process, save_function=accelerator.save)\n        \n    except Exception as e:\n        accelerator.print(e)\n        \n        accelerator.wait_for_everyone() \n        model = accelerator.unwrap_model(model)\n        model.save_pretrained('checkpoint', is_main_process=accelerator.is_main_process, save_function=accelerator.save)\n        raise e\n\n","metadata":{"id":"9nucF16hUfnA","execution":{"iopub.status.busy":"2023-05-09T22:00:40.113852Z","iopub.execute_input":"2023-05-09T22:00:40.114246Z","iopub.status.idle":"2023-05-09T22:00:40.126219Z","shell.execute_reply.started":"2023-05-09T22:00:40.114209Z","shell.execute_reply":"2023-05-09T22:00:40.125308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from accelerate import notebook_launcher\nprint('train')\nnotebook_launcher(train, args=(model,),num_processes=torch.cuda.device_count()) ","metadata":{"id":"T7MioJoDtGcw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = XGLMForCausalLM.from_pretrained('/kaggle/working/checkpoint', local_files_only=True,torch_dtype=torch.float16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generation_config = GenerationConfig(\n        temperature=0.1,\n        top_p=0.75,\n        top_k=40,\n        num_beams=4,\n    )\ndevice = torch.device('cuda')\nsample.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef gen(prompt,generation_config=generation_config):\n    prompt = f'{prompt} <human>:'\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n    input_ids = input_ids.to(device)\n    with torch.no_grad():\n        generation_output = sample.generate(\n            input_ids=input_ids,\n            generation_config=generation_config,\n            return_dict_in_generate=True,\n            output_scores=True,\n            max_new_tokens=256,\n        )\n    output_1_ids = generation_output.sequences[0]\n    output = tokenizer.decode(output_1_ids)  \n    bot_prompt = re.split(tokenizer.eos_token,output)[1]\n    bot_prompt = f'{bot_prompt} <bot>:'\n    inputs = tokenizer(bot_prompt, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n    input_ids = input_ids.to(device)\n    with torch.no_grad():\n        generation_output = sample.generate(\n            input_ids=input_ids,\n            generation_config=generation_config,\n            return_dict_in_generate=True,\n            output_scores=True,\n            max_new_tokens=256,\n        )\n    s = generation_output.sequences[0]\n    output = tokenizer.decode(s)\n    res = re.split('<human>: | <bot>:',output)\n    if len(res) == 3:\n        return f'<human>: {res[1]} \\n<bot>: {res[2]}'\n    else:\n        return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_prompt = \"\"\"\nDoraemon  is a Japanese manga series written and illustrated \nby Fujiko F. Fujio. The manga was first serialized in December 1969, \nwith its 1,345 individual chapters compiled into 45 tank≈çbon volumes \nand published by Shogakukan from 1970 to 1996. The story revolves around \nan earless robotic cat named Doraemon, who travels back in time from the \n22nd century to aid a boy named Nobita Nobi.\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = gen(sample_prompt)\nprint(response)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}